<img src="https://bit.ly/2VnXWr2" alt="Ironhack Logo" width="100"/>

# What does it take to be a Software Developer? 
## A machine learning algorithm to predict your probabilities of becoming a software developer

*By:
Inês Garcia*

*Data Squad #21  
Lisbon  
October 2019*

## Content
- [Project Description](#project-description)
- [Hypotheses / Questions](#hypotheses-/-questions)
- [Dataset](#dataset)
- [Workflow](#workflow)
- [Links](#links)

<a name="project-description"></a>

## Project Description
Using the freeCodeCamp's New Coder Survey results from 2016, 2017 and 2018 we created a ML algorithm that predicts the probabilities of becoming a Sotware Developer, based on your coding experience as well as other resources used to learn code and improve your skills. 
The main goal of this project was to create a software that can help bootcamp staff to target and adequate strategies to help their students to get a job after undertaking a Bootcamp. 

All the notebooks can be found in the respective folder. 

<a name="hypotheses-/-questions"></a>

## Hypotheses / Questions
Overall we intended to understand how climate event impact business, in particular energy companies.

After the initial analysis of the data available other two hypothesis arose:
1. What are the most relevant features to become a software developer?
2. Are Bootcamps relevant to get a software development job?

<a name="dataset"></a>

## Dataset
The data used is from the freeCodeCamp's New Coder Survey of 2016, 2017 and 2018. 

[2018](https://github.com/freeCodeCamp/2018-new-coder-survey)  
[2017](https://github.com/freeCodeCamp/2017-new-coder-survey)  
[2016](https://github.com/freeCodeCamp/2016-new-coder-survey)


<a name="workflow"></a>

## Workflow

1. Research and data collection: We started by deciding on the subject and search for availabe data, collecting the most relevant. After this we questioned what did we wanted to know and what could be answered by the information availabe.
2. Data cleaning and database creation: After identifying the most relevant data we proceded to its cleaning and manipulation. The data was cleanned using pandas in Jupyter Notebook. 
3. Insights and conclusions
4. Final presentation. 

<a name="links"></a>

## Links
[Inês Garcia Repository](https://github.com/Inrx)    
[Public Presentation](https://www.canva.com/design/DADnD8FVZzM/htOI-9yqGsD7CFn5wpMR4A/view?utm_content=DADnD8FVZzM&utm_campaign=designshare&utm_medium=link&utm_source=sharebutton)   
